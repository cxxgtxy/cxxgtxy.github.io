---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Short  Bio
======

As a senior technical manager in Meituan, I lead 30 outstanding researchers and engineers, focus on AI research and application. Our team  cover a wide range of topics, including basic model design, NAS, model compression, self-supervised learning, 2D perception (classification, segmentation, detection), 3D detection, LLM pre-training, multi-modal large models, reinforcement learning, generative models.  I Published 15 papers at top AI conferences (9 as first author).  Three of my first-authored papers were selected for the PaperDigest's most influential paper list (FairNAS-ICCV, Twins-NeurIPS, CPVT-ICLR). I hold over 40 domestic and 7 international invention patents. I have experience managing technical teams of over 30 people and extensive experience in implementing AI (vision, voice, search and recommendation) projects. I am adept at building influential teams, tackling tough challenges, and delivering strong results.

*We are always looking for talented interns/full-time researchers with strong coding skills and research experience. Please drop me an email if interested.*



Education
======
* B.S. in EE, SouthEast University, 2010
* M.S. in EE, Tsinghua University, 2012 

Work experience
======
* May 2020 - Present, Meituan, Visual Intelligence Department, Senior Technical Manager
  * Team direction: Multi-modal large models，Large Language Model, perception (2D+3D), basic model design, self-supervised pre-training, model compression, MLOps.
    * Core technology breakthroughs in autonomous driving and drones: Building the 3D offline system for autonomous delivery vehicles, saving the business many million in annotation costs annually, improving online perception algorithms (3D obstacle detection, tracking), helping the autonomous vehicle team achieve industry-leading real-time perception capabilities; improving the level of automated mapping for high-precision maps. Several core perception modules have been launched on the third and fourth generation drones. 
    * Large models (LLM and multi-modal): Responsible for building a general understanding (multi-modal) large model, open set understanding, and landing in Meituan scenarios; compression and efficient deployment of the company's trillion LLM, the self-developed model quantization technology reaches the advanced level in the industry; responsible for the training and deployment of the LLM base model for the general intelligent robot (embodied intelligence) scene.
    * Broad AI business support and MLOps construction: Construction of a general vision code library, construction of AutoML general tools, support for the compression and deployment (end, edge, cloud) of the department's deep learning models, covering most of the company's vision applications and services such as face recognition, OCR, security review, image understanding, maps, saving many million in vision service costs annually.
    * Team building: Building a team from 0 to 1, completing interviews with multiple Google PHD Fellowship, attracting top talents recognized in the industry.
    * Influence building:  open sourcing and maintaining the well-known detection library YOLOv6; as a project backbone, undertaking the national science and technology innovation 2030 major special project 3.3 research on key technologies of artificial intelligence basic models.
* March 2017 - May 2020, Xiaomi, Artificial Intelligence Department, Senior Technical Manager
  * Team direction: AutoML, basic model design, machine learning.
  * Initiated the AutoML project, built the AutoML team from 0 to 1, responsible for all-round technical research, algorithm development and implementation. Implemented in multiple businesses such as scene recognition, segmentation, acoustic scene classification, recommendation, etc.
Lead the team and  won the second place ("Automated Neural Network Design") in the first "Million Dollar Prize" of Xiaomi Company.
  
* June 2013 - March 2017, Beijing Qingda Gaoke System Control Co., Ltd., Deputy Technical Director
  * As a technical backbone, participated in the "Complex Power Grid Autonomy - Collaborative Automatic Voltage Control Key Technology, System Development and Engineering Application" project, which was awarded the 2018 National Science and Technology Progress First Prize (contributing 20 invention patents).

* July 2012 - May 2013, IBM China Research Institute, Research Scientist

Publications
======
First-author papers

<ol>
  <li>Twins: Revisiting the design of spatial attention in vision transformers, NeurIPS21</li>
  <li>Conditional Positional Encodings for Vision Transformers, ICLR23</li>
  <li>FairNAS: Rethinking evaluation fairness of weight sharing neural architecture search, ICCV21 </li>
  <li>Fair DARTS: Eliminating unfair advantages in differentiable architecture search, ECCV20</li>
  <li>DARTS-: robustly stepping out of performance collapse without indicators, ICLR21</li>
  <li>Noisy differentiable architecture search, BMVC21</li>
  <li>Multi-objective reinforced evolution in mobile neural architecture search, ECCVW2020</li>
  <li>Fast, accurate and lightweight super-resolution with neural architecture search, ICPR20</li>
  <li>MoGA: Searching beyond mobilenetv3, ICASSP2020</li>
  <li>Scarlet-NAS: bridging the gap between stability and scalability in weight-sharing neural architecture search, ICCVW21</li>
  <li>A Unified Mixture-View Framework for Unsupervised Representation Learning, BMVC22</li>
  <li>Parameter sharing deep deterministic policy gradient for cooperative multi-agent reinforcement learning</li>
  <li>Improved crowding distance for NSGA-II</li>
  <li>Policy optimization with penalized point probability distance: An alternative to proximal policy optimization</li>
  <li>ROME: Robustifying memory-efficient nas via topology disentanglement and gradients accumulation , ICCV23</li>
  <li>Make RepVGG Greater Again: A Quantization-aware Approach</li>
  <li>MixPATH: A unified approach for one-shot neural architecture search，ICCV23</li>
</ol>

Other Collaborative Papers 
<ol>
  <li>Promptdet: Towards open-vocabulary detection using uncurated images, ECCV22</li>
  <li>SegVIT: Semantic segmentation with plain vision transformers, NeurIPS22</li>
  <li>Fully convolutional one-stage 3D object detection on LiDAR range images, NeurIPS22</li>
  <li>Modeling Motion with Multi-Modal Features for Text-Based Video Segmentation, CVPR22</li>
  <li>Aedet: Azimuth-invariant multi-view 3d object detection, CVPR23</li>
  <li>EAPruning: Evolutionary Pruning for Vision Transformers and CNNs, BMVC22</li>
  <li>AutoKWS: Keyword Spotting with Differentiable Architecture Search, ICASSP21</li>
  <li>Neural Architecture Search on Acoustic Scene Classification, InterSpeech20</li>
  <li>Accurate and efficient single image super-resolution with matrix channel attention network, ACCV20</li>
  <li>STRETCH meat grinder with ICCOS, IEEE Transactions on Plasma Science</li>
  <li>Comparisons of three inductive pulse power supplies, IEEE Transactions on Plasma Science</li>
  <li>YOLOv6: A single-stage object detection framework for industrial applications</li>
  <li>FastPillars: A Deployment-friendly Pillar-based 3D Detector</li>
  <li>Norm Tweaking: High-performance Low-bit Quantization of Large Language Models</li>
</ol>




